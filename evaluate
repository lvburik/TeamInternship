import torch
from transformers import SegformerForSemanticSegmentation
import torch.nn as nn
from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor
import torch
from Resin_plates import *
from data import *
import numpy as np
import glob
import os
from PIL import Image
from scipy.ndimage import gaussian_filter
import tensorflow as tf
import numpy as np
from PIL import Image
import torch
from torchvision import transforms
import os
import numpy as np
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.optim as optim
from torch.optim import AdamW
import matplotlib.pyplot as plt
from transformers import Trainer, TrainingArguments
from transformers import SegformerForSemanticSegmentation, SegformerFeatureExtractor
import piq
from torchmetrics.functional import structural_similarity_index_measure as ssim
import torch.nn.functional as F
from torchmetrics import JaccardIndex
from segmentation_models_pytorch.losses import DiceLoss


feature_extractor = SegformerImageProcessor.from_pretrained("nvidia/segformer-b0-finetuned-ade-512-512")
model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b0-finetuned-ade-512-512", ignore_mismatched_sizes=True, num_labels=2)
model.decode_head.classifier = nn.Conv2d(
    in_channels=256,
    out_channels=2,  # number of classes you want
    kernel_size=1
)
weights_path = "segformer_weights_for_15_epochs_all.pth"
state_dict = torch.load(weights_path, map_location="cpu")  # or "cuda" if GPU available

# Load state dict into the model
model.load_state_dict(state_dict)
model.eval()

########################################

resin_folder="data"
r_data=glob.glob(os.path.join(resin_folder,"*.npy"))
resin_data=[]
print("a is done")

path = "Resin_plates/circular.png"
image=Image.open(path)
mask_c=np.array(image)
#print(mask_c.shape)

path_c = "Resin_plates/rec.png"
image_c=Image.open(path_c)
mask_rec=np.array(image_c)
#print(mask_rec.shape)

path_s = "Resin_plates/square.png"
image_s=Image.open(path_s)
mask_s=np.array(image_s)
#print(mask_s.shape)

path_t = "Resin_plates/tri.png"
image_t=Image.open(path_t)
mask_t=np.array(image_t)
#print(mask_t.shape)

print("Masks are loaded")

# Assume video shape (1443, 480, 640)
video_one = np.load(r_data[0]).reshape(-1, 480, 640)
video_two = np.load(r_data[1]).reshape(-1, 480, 640)
video_three = np.load(r_data[2]).reshape(-1,480, 640)
video_four = np.load(r_data[3]).reshape(-1,480, 640)
video_five = np.load(r_data[4]).reshape(-1,480, 640)
video_six = np.load(r_data[5]).reshape(-1,480, 640)

video_files = [video_one, video_two, video_three, video_four, video_five,video_six]  
masks=[mask_c, mask_rec, mask_s, mask_rec]
frames=[]

print("videos are loaded")

for video in video_files:
    sampling_rate = 30
    sampled_frames = video[::sampling_rate]
    frames.append(sampled_frames)
print(f" First dimension is {len(frames)}")
print(f" Second dimension is {len(frames[0])}")

all_frames=[item for sublist in frames for item in sublist]
all_frames=all_frames[95:115]
print(f"Total number of frames is {len(all_frames)}")

###########################################################################
INPUT_SIZE = 512 
temp_min = 20.82
temp_max = 31.68
input_size = 256
batch_size = 16
num_epochs = 15
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def preprocess(frame, min, max):
    norm_frame = (frame - np.min(frame)) / (max - min)
#print(f"After normalization: {norm_frame}")
    norm_frame = np.clip(norm_frame, 0, 1)
#print(f"After clipping: {norm_frame}")
    norm_frame=norm_frame.astype(np.float32)
#print(f"New one: {norm_frame}")
    norm_frame=np.squeeze(norm_frame)
    rgb = plt.cm.jet(norm_frame)[:, :,:3]
    norm_frame_uint8 = (rgb * 255).astype(np.uint8) 
    pil_img = Image.fromarray(norm_frame_uint8)
#print(rgb)
#print(len(rgb))
#print(len(rgb[0]))
    return pil_img

def label_tensor(mask):
    label = Image.fromarray(mask.astype(np.uint8))
    mask_resized = label.resize((512, 512), resample=Image.NEAREST) 
    label_tensor = torch.tensor(np.array(mask_resized), dtype=torch.long)
    label_tensor=label_tensor.unsqueeze(0)
    return label_tensor

circle=label_tensor(mask_c)
rec=label_tensor(mask_rec)
square=label_tensor(mask_s)
tri=label_tensor(mask_t)

def dataset(frames, video):
    list_frames=[]
    for f in frames:
        pr_frame=preprocess(f, video.min(), video.max())
        list_frames.append(pr_frame)
    encoded_frames=feature_extractor(list_frames, return_tensors="pt")
    v1 = circle.repeat(48, 1, 1) 
    v2 = circle.repeat(48, 1, 1)
    v3 =  rec.repeat(48, 1, 1) 
    v4 = square.repeat(48, 1, 1)
    v5 = square.repeat(48, 1, 1)
    v6 = tri.repeat(48, 1, 1) 
    all_labels = torch.cat([v1, v2, v3, v4, v5, v6], dim=0)
    encoded_frames["labels"]=all_labels
    return encoded_frames


class ImageDataset(Dataset):
    def __init__(self, pixel_values, labels):
        self.pixel_values = pixel_values
        self.labels = labels

    def __len__(self):
        return self.pixel_values.shape[0]

    def __getitem__(self, idx):
        return {
            'pixel_values': self.pixel_values[idx],
            'labels': self.labels[idx]
        }
        
validation_dataset=dataset(all_frames, video_one)
print(validation_dataset)


with torch.no_grad():
    outputs = model(validation_dataset["pixel_values"])

# Extract logits and convert to predicted class masks
logits = outputs.logits  # shape: (batch_size, num_classes, height, width)
logits_upsampled = F.interpolate(logits, size=(512, 512), mode='bilinear', align_corners=False)
predicted_mask = logits_upsampled.argmax(dim=1)  # predicted class per pixel
#probs = F.softmax(logits_upsampled, dim=1)
#soft_probs = probs[:, 1, :, :]
#print(f"Shape of prediction is {predicted_mask.shape}")
#print(f"Shape of the label is {circle.shape}")
#print(f"Preeicted mask is {predicted_mask}")


rec_mask=rec.repeat(len(all_frames),1,1)


def binary_precision_recall_f1(pred, target, positive_class=1):
    pred = pred.view(-1)
    target = target.view(-1)

    TP = ((pred == positive_class) & (target == positive_class)).sum().item()
    FP = ((pred == positive_class) & (target != positive_class)).sum().item()
    FN = ((pred != positive_class) & (target == positive_class)).sum().item()

    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0
    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0

    return precision, recall, f1

precision, recall, f1 = binary_precision_recall_f1(predicted_mask, rec_mask)



print(f"Precision is {precision}")
print(f"Recall is {recall}")
print(f"F1 score is {f1}")

predicted_mask=predicted_mask.float()
predicted_mask_4d = F.interpolate(predicted_mask[3].unsqueeze(0).unsqueeze(0), size=(480, 640), mode='bilinear', align_corners=False)
predicted_mask_resized=predicted_mask_4d.squeeze(0).squeeze(0)


plt.imshow(predicted_mask_resized.cpu(), cmap='gray')  # use cmap='gray' for grayscale images
plt.title('Predicted mask')
plt.axis('off')  # hide axis ticks
plt.show()






 

